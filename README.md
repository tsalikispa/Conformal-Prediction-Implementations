# ğŸ§  Conformal Prediction Implementations

This repository contains concise, educational implementations of **Conformal Prediction (CP)** using both **NumPy**/**SciPY** and **TorchCP**.  
It illustrates how to construct reliable, **distribution-free prediction sets** that quantify model uncertainty and ensure coverage guarantees.

---

## ğŸ§­ Overview

This project demonstrates the practical and theoretical aspects of **distribution-free uncertainty quantification** through two complementary implementations:

- ğŸ§® **NumPy Implementation** â€” a fully transparent, from-scratch version for educational and research purposes using only NumPy and SciPy.  
- âš™ï¸ **TorchCP Implementation** â€” deep learningâ€“based examples leveraging PyTorch and the open-source [TorchCP](https://github.com/ml-stat-Sustech/TorchCP) library.

These implementations aim to highlight:
- How conformal prediction ensures valid **coverage calibration**
- Construction of **prediction sets** under minimal assumptions
- Comparison between classical and neural methods

---



## ğŸ“‚ Repository Structure

```text
Conformal-Prediction-Implementations/
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ pure_python/      # NumPy / SciPy from-scratch implementations
â”‚   â””â”€â”€ torch_cp/         # PyTorch + TorchCP implementations
â”‚
â””â”€â”€ notebooks/            # Jupyter notebooks with demos & visualizations


ğŸ“š References

Angelopoulos, A. N., & Bates, S. (2022).
A Gentle Introduction to Conformal Prediction and Distribution-Free Uncertainty Quantification.
arXiv preprint arXiv:2107.07511


